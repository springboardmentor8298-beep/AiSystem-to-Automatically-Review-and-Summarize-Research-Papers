{
  "abstract": "abstract\nblack box machine learning models are currently being used for\nhigh-stakes decision making throughout society, causing problems\nin healthcare, criminal justice and other domains. some people\nhope that creating methods for explaining these black box models\nwill alleviate some of the problems, but trying to explain black box\nmodels, rather than creating models that are interpretable in the\nfirst place, is likely to perpetuate bad practice and can potentially\ncause great harm to society. the way forward is to design models\nthat are inherently interpretable. this perspective clarifies the\nchasm between explaining black boxes and using inherently\ninterpretable models, outlines several key reasons why explainable\nblack boxes should be avoided in high-stakes decisions, identifies\nchallenges to interpretable machine learning, and provides several\nexample applications where interpretable models could potentially\nreplace black box models in criminal justice, healthcare and\ncomputer vision.\n access through your institution\nbuy or subscribe\nthis is a preview of subscription content, access via your institution\naccess options\n access through your institution\naccess nature and 54 other nature portfolio journals\nget nature+, our best-value online-access subscription\n27,99\u00a0\u20ac /\u00a030\u00a0days\ncancel any time\nlearn more\nsubscribe to this journal\nreceive 12 digital issues and online access to articles\n111,21\u00a0\u20ac per year\nonly 9,27 \u20ac per issue\nlearn more\nbuy this article\n\u2022  purchase on springerlink\n\u2022  instant access to the full article pdf.\n39,95 \u20ac\nprices may be subject to local taxes which are calculated during\ncheckout\nadditional access options:\n\u2022  log in\n\u2022  learn about institutional subscriptions\n\u2022  read our faqs\n\u2022  contact customer support\nfig. 1: a fictional depiction of the accuracy\u2013interpretability\ntrade-off.\n[image]\nfig. 2: saliency does not explain anything except where the\nnetwork is looking.\n[image]\nfig. 3: image from the authors of ref. 48, indicating that parts\nof the test image on the left are similar to prototypical parts of\ntraining examples.\n[image]\nsimilar content being viewed by others\n[image]\nachieving interpretable machine learning by\nfunctional decomposition of black-box models into\nexplainable predictor effects\narticle open access 03 november 2025\n[image]\nthermodynamics-inspired explanations of artificial\nintelligence\narticle open access 09 september 2024\n[image]\nblack box problem and african views of trust\narticle open access 14 october 2023\nreferences\n1. wexler, r. when a computer program keeps you in jail: how\ncomputers are harming criminal justice. new york times (13\njune 2017); https://www.nytimes.com/2017/06/13/\nopinion/how-computers-are-harming-criminal-justice.html\n2. mcgough, m. how bad is sacramento\u2019s air, exactly? google",
  "results": "results appear at odds with reality, some say. sacramento bee\n(7 august 2018); https://www.sacbee.com/news/state/\ncalifornia/fires/article216227775.html\n3. varshney, k. r. & alemzadeh, h. on the safety of machine\nlearning: cyber-physical systems, decision sciences and data\nproducts. big data 10, 5 (2016).\ngoogle scholar\u00a0\n4. freitas, a. a. comprehensible classification models: a position\npaper. acm sigkdd explorations newsletter 15, 1\u201310 (2014).\narticle\u00a0 google scholar\u00a0\n5. kodratoff, y. the comprehensibility manifesto. kdd nugget\nnewsletter https://www.kdnuggets.com/news/94/n9.txt\n(1994).\n6. huysmans, j., dejaeger, k., mues, c., vanthienen, j. &\nbaesens, b. an empirical evaluation of the comprehensibility\nof decision table, tree and rule based predictive models.\ndecision support syst. 51, 141\u2013154 (2011).\narticle\u00a0 google scholar\u00a0\n7. r\u00fcping, s. learning interpretable models. phd thesis, univ.\ndortmund (2006).\n8. gupta, m. et al. monotonic calibrated interpolated look-up\ntables. j. mach. learn. res. 17, 1\u201347 (2016).\nmathscinet\u00a0 math\u00a0 google scholar\u00a0\n9. lou, y., caruana, r., gehrke, j. & hooker, g. accurate\nintelligible models with pairwise interactions. in proceedings\nof 19th acm sigkdd international conference on knowledge\ndiscovery and data mining 623\u2013631 (acm, 2013).\n10. miller, g. the magical number seven, plus or minus two:\nsome limits on our capacity for processing information.\npsychol. rev. 63, 81\u201397 (1956).\narticle\u00a0 google scholar\u00a0\n11. cowan, n. the magical mystery four: how is working\nmemory capacity limited, and why? curr. dir. psychol. sci. 19,\n51\u201357 (2010).\narticle\u00a0 google scholar\u00a0\n12. wang, j., oh, j., wang, h. & wiens, j. learning credible\nmodels. in proceedings of 24th acm sigkdd international\nconference on knowledge discovery and data mining 2417\u2013\n2426 (acm, 2018).\n13. rudin, c. please stop explaining black box models for high\nstakes decisions. in proceedings of neurips 2018 workshop on\ncritiquing and correcting trends in machine learning (nips,\n2018).\n14. holte, r. c. very simple classification rules perform well on\nmost commonly used datasets. mach. learn. 11, 63\u201391\n(1993).\narticle\u00a0 google scholar\u00a0\n15. fayyad, u., piatetsky-shapiro, g. & smyth, p. from data\nmining to knowledge discovery in databases. ai magazine 17,\n37\u201354 (1996).\ngoogle scholar\u00a0\n16. chapman, p. et al. crisp-dm 1.0\u2014step-by-step data mining\nguide (spss, 2000).\n17. agrawal, d. et al. challenges and opportunities with big data: a\nwhite paper prepared for the computing community consortium\ncommittee of the computing research association (ccc, 2012);\nhttp://cra.org/ccc/resources/ccc-led-whitepapers/\n18. defense advanced research projects agency. broad agency\nannouncement, explainable artificial intelligence (xai), darpa-\nbaa-16-53 (darpa, 2016); https://www.darpa.mil/\nattachments/darpa-baa-16-53.pdf\n19. hand, d. classifier technology and the illusion of progress.\nstatist. sci. 21, 1\u201314 (2006).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n20. rudin, c. et al. a process for predicting manhole events in\nmanhattan. mach. learn. 80, 1\u201331 (2010).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n21. rudin, c. & ustun, b. optimized scoring systems: toward trust\nin machine learning for healthcare and criminal justice.\ninterfaces. 48, 399\u2013486 (2018). special issue: 2017 daniel h.\nwagner prize for excellence in operations research practice\nseptember\u2013october 2018.\narticle\u00a0 google scholar\u00a0\n22. chen, c. et al. an interpretable model with globally\nconsistent explanations for credit risk. in proceedings of\nneurips 2018 workshop on challenges and opportunities for ai\nin financial services: the impact of fairness, explainability,\naccuracy, and privacy (nips, 2018).\n23. mittelstadt, b., russell, c. & wachter, s. explaining\nexplanations in ai. in proceedings of fairness, accountability,\nand transparency (fat*) (acm, 2019).\n24. flores, a. w., lowenkamp, c. t. & bechtel, k. false positives,\nfalse negatives, and false analyses: a rejoinder to \u2018machine\nbias: there\u2019s software used across the country to predict future\ncriminals\u2019. fed. probat. j. 80, 38\u201346 (2016).\ngoogle scholar\u00a0\n25. angwin, j., larson, j., mattu, s. & kirchner, l. machine bias.\npropublica (2016); https://www.propublica.org/article/\nmachine-bias-risk-assessments-in-criminal-sentencing\n26. larson, j., mattu, s., kirchner, l. & angwin, j. how we\nanalyzed the compas recidivism algorithm. propublica\n(2016); https://www.propublica.org/article/how-we-\nanalyzed-the-compas-recidivism-algorithm\n27. rudin, c., wang, c.& coker, b. the age of secrecy and\nunfairness in recidivism prediction. preprint at https://\narxiv.org/abs/1811.00731 (2018).\n28. brennan, t., dieterich, w. & ehret, b. evaluating the\npredictive validity of the compas risk and needs assessment\nsystem. crim. justice behav. 36, 21\u201340 (2009).\narticle\u00a0 google scholar\u00a0\n29. zeng, j., ustun, b. & rudin, c. interpretable classification\nmodels for recidivism prediction. j. r. stat. soc. a stat. soc.\n180, 689\u2013722 (2017).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n30. tollenaar, n. & van der heijden, p. g. m. which",
  "method": "method\npredicts recidivism best? a comparison of statistical, machine\nlearning and data mining predictive models. j. r. stat. soc.\nser. a stat. soc. 176, 565\u2013584 (2013).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n31. mannshardt, e. & naess, l. air quality in the usa. significance\n15, 24\u201327 (october, 2018).\n32. zech, j. r. et al. variable generalization performance of a\ndeep learning model to detect pneumonia in chest\nradiographs: a cross-sectional study. plos med. 15, e1002683\n(2018).\narticle\u00a0 google scholar\u00a0\n33. chang, a., rudin, c., cavaretta, m., thomas, r. & chou, g.\nhow to reverse-engineer quality rankings. mach. learn. 88,\n369\u2013398 (2012).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n34. goodman, b. & flaxman, s. eu regulations on algorithmic\ndecision-making and a \u2018right to explanation\u2019. ai magazine 38,\n3 (2017).\narticle\u00a0 google scholar\u00a0\n35. wachter, s., mittelstadt, b. & russell, c. counterfactual\nexplanations without opening the black box: automated\ndecisions and the gdpr. harvard journal of law & technology\n1 (2018).\n36. quinlan, j. r. c4. 5: programs for machine learning vol. 1\n(morgan kaufmann, 1993).\n37. breiman, l., friedman, j., stone, c. j. & olshen, r. a.\nclassification and regression trees (crc press, 1984).\n38. auer, p., holte, r. c. & maass, w. theory and applications of\nagnostic pac-learning with small decision trees. in\nproceedings of 12th international conference on machine\nlearning 21\u201329 (morgan kaufmann, 1995).\n39. angelino, e., larus-stone, n., alabi, d., seltzer, m. & rudin,\nc. certifiably optimal rule lists for categorical data. j. mach.\nlearn. res. 19, 1\u201379 (2018).\nmathscinet\u00a0 math\u00a0 google scholar\u00a0\n40. wang, f. & rudin, c. falling rule lists. in proceedings of\nmachine learning research vol. 38: artificial intelligence and\nstatistics 1013\u20131022 (pmlr, 2015).\n41. chen, c. & rudin, c. an optimization approach to learning\nfalling rule lists. in proceedings of machine learning research\nvol. 84 : artificial intelligence and statistics 604\u2013612 (pmlr,\n2018).\n42. hu, x. (s.), rudin, c. & seltzer, m. optimal sparse decision\ntrees. preprint at https://arxiv.org/abs/1904.12847 (2019).\n43. burgess, e. w. factors determining success or failure on parole\n(illinois committee on indeterminate-sentence law and\nparole, 1928).\n44. carrizosa, e., martn-barrag\u00e1n, b. & morales, d. r. binarized\nsupport vector machines. informs j. comput. 22, 154\u2013167\n(2010).\narticle\u00a0 mathscinet\u00a0 google scholar\u00a0\n45. sokolovska, n., chevaleyre, y. & zucker, j. d. a provable\nalgorithm for learning interpretable scoring systems. in\nproceedings of machine learning research vol. 84: artificial\nintelligence and statistics 566\u2013574 (pmlr, 2018).\n46. ustun, b. & rudin, c. optimized risk scores. in proceedings of\nthe 23rd acm sigkdd international conference on knowledge\ndiscovery and data mining (acm, 2017).\n47. ustun, b. et al. the world health organization adult\nattention-deficit/hyperactivity disorder self-report screening\nscale for dsm-5. jama psychiatr. 74, 520\u2013526 (2017).\narticle\u00a0 google scholar\u00a0\n48. chen, c. et al. this looks like that: deep learning for\ninterpretable image recognition. preprint at https://arxiv.org/\nabs/1806.10574 (2018).\n49. li, o., liu, h., chen, c. & rudin, c. deep learning for case-\nbased reasoning through prototypes: a neural network that\nexplains its predictions. in proceedings of aaai conference on\nartificial intelligence 3530\u20133537 (aaai, 2018).\n50. gallagher, n. et al. cross-spectral factor analysis. in\nproceedings of advances in neural information processing\nsystems 30 (neurips) 6842\u20136852 (curran associates, 2017).\n51. wang, f., rudin, c., mccormick, t. h. & gore, j. l. modeling\nrecovery curves with application to prostatectomy.\nbiostatistics https://doi.org/10.1093/biostatistics/kxy002\n(2018).\n52. lou, y., caruana, r. & gehrke, j. intelligible models for\nclassification and regression. in proceedings of the 18th acm\nsigkdd international conference on knowledge discovery and\ndata mining (acm, 2012).\ndownload references\nacknowledgements\nthe author thanks f. wang, t. wang, c. chen, o. li, a. barnett, t.\ndietterich, m. seltzer, e. angelino, n. larus-stone, e. mannshart, m.\ngupta and several others who helped my thought processes in\nvarious ways, and particularly b. ustun, r. parr, r. holte and my\nfather, s. rudin, who went to considerable efforts to provide\nthoughtful comments and discussion. the author acknowledges\nfunding from the laura and john arnold foundation, nih, nsf,\ndarpa, the lord foundation of north carolina and mit-lincoln\nlaboratory.\nauthor information\nauthors and affiliations\n1. duke university, durham, nc, usa\ncynthia rudin\nauthors\n1. cynthia rudin\nview author publications\nsearch author on:pubmed\u00a0google scholar\ncorresponding author\ncorrespondence to cynthia rudin.\nethics declarations\ncompeting interests\nthe author declares no competing interests.\nadditional information\npublisher\u2019s note: springer nature remains neutral with regard to\njurisdictional claims in published maps and institutional affiliations.\nsupplementary information\nsupplementary information\nrights and permissions\nreprints and permissions\nabout this article\n[image]\ncite this article\nrudin, c. stop explaining black box machine learning models for\nhigh stakes decisions and use interpretable models instead. nat\nmach intell 1, 206\u2013215 (2019). https://doi.org/10.1038/\ns42256-019-0048-x\ndownload citation\n\u2022  received: 30 december 2018\n\u2022  accepted: 26 march 2019\n\u2022  published: 13 may 2019\n\u2022  version of record: 13 may 2019\n\u2022  issue date: may 2019\n\u2022  doi: https://doi.org/10.1038/s42256-019-0048-x\nshare this article\nanyone you share the following link with will be able to read this\ncontent:\nget shareable link\nsorry, a shareable link is not currently available for this article.\ncopy shareable link to clipboard\nprovided by the springer nature sharedit content-sharing initiative\nthis article is cited by\n\u2022  rethinking sepsis prediction in the era of large\nlanguage models\n\u25cb  andrew wong\n\u25cb  karandeep singh\n\u25cb  shamim nemati\nnpj health systems (2026)\n\u2022  digital twins for personalized treatment in uro-\noncology in the era of artificial intelligence\n\u25cb  magdalena g\u00f6rtz\n\u25cb  carlos brandl\n\u25cb  matthias weidem\u00fcller\nnature reviews urology (2026)\n\u2022  interpretable deep learning reveals distinct\nspectral and temporal drivers of perceived\nmusical emotion\n\u25cb  yiming gu\n\u25cb  chen shao\n\u25cb  yinghan fan\nscientific reports (2026)\n\u2022  interpretable multimodal zero shot ecg\ndiagnosis via structured clinical knowledge\nalignment\n\u25cb  jialu tang\n\u25cb  hung manh pham\n\u25cb  aaqib saeed\nnpj cardiovascular health (2026)\n\u2022  critical engagement: the value of transparency\nof ai in healthcare\n\u25cb  james edgar lim\n\u25cb  owen schaefer\n\u25cb  julian savulescu\nphilosophy & technology (2026)\n access through your institution\nbuy or subscribe\nassociated content\nspecial\none year anniversary collection\nadvertisement\n[image]\nexplore content\n\u2022  research articles\n\u2022  reviews & analysis\n\u2022  news & comment\n\u2022  videos\n\u2022  current issue\n\u2022  collections\n\u2022  follow us on twitter\n\u2022  subscribe\n\u2022  sign up for alerts\n\u2022  rss feed\nabout the journal\n\u2022  aims & scope\n\u2022  journal information\n\u2022  journal metrics\n\u2022  about the editors\n\u2022  our publishing models\n\u2022  editorial values statement\n\u2022  editorial policies\n\u2022  content types\n\u2022  contact\n\u2022  research cross-journal editorial team\n\u2022  reviews cross-journal editorial team\npublish with us\n\u2022  submission guidelines\n\u2022  for reviewers\n\u2022  language editing services\n\u2022  open access funding\n\u2022  submit manuscript\nsearch\nsearch articles by subject, keyword or author\nshow results from all journals this journal\nsearch\nadvanced search\nquick links\n\u2022  explore articles by subject\n\u2022  find a job\n\u2022  guide to authors\n\u2022  editorial policies\nnature machine intelligence (nat mach intell)\nissn 2522-5839 (online)\nnature.com sitemap\nabout nature portfolio\n\u2022  about us\n\u2022  press releases\n\u2022  press office\n\u2022  contact us\ndiscover content\n\u2022  journals a-z\n\u2022  articles by subject\n\u2022  protocols.io\n\u2022  nature index\npublishing policies\n\u2022  nature portfolio policies\n\u2022  open access\nauthor & researcher services\n\u2022  reprints & permissions\n\u2022  research data\n\u2022  language editing\n\u2022  scientific editing\n\u2022  nature masterclasses\n\u2022  research solutions\nlibraries & institutions\n\u2022  librarian service & tools\n\u2022  librarian portal\n\u2022  open research\n\u2022  recommend to library\nadvertising & partnerships\n\u2022  advertising\n\u2022  partnerships & services\n\u2022  media kits\n\u2022  branded content\nprofessional development\n\u2022  nature awards\n\u2022  nature careers\n\u2022  nature conferences\nregional websites\n\u2022  nature africa\n\u2022  nature china\n\u2022  nature india\n\u2022  nature japan\n\u2022  nature middle east\n\u2022  privacy policy\n\u2022  use of cookies\n\u2022  your privacy choices/manage cookies\n\u2022  legal notice\n\u2022  accessibility statement\n\u2022  terms & conditions\n\u2022  your us state privacy rights\n[image]\n\u00a9 2026 springer nature limited\n close\n[image]\nsign up for the nature briefing: ai and robotics newsletter \u2014 what\nmatters in ai and robotics research, free to your inbox weekly.\nemail address\nsign up\ni agree my information will be processed in accordance with the\nnature and springer nature limited privacy policy.\n close\nget the most important science stories of the day, free in your\ninbox. sign up for nature briefing: ai and robotics\n[image]"
}