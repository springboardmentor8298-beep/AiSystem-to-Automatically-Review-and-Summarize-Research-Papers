SYNTHESIZED SECTION
===================

introduction machine learning algorithms have penetrated every aspect of our lives. algorithms make movie recommendations, suggest products to buy, and who to date. they are increasingly used in high-stakes scenarios such as loans [113] and hiring decisions [19, 39]. there are clear benefits to algorithmic decision-making; unlike people, machines do not become tired or bored [45, 119], and can take into account orders of magnitude more factors than people can. however, like people, algorithms are vulnerable to biases that render their decisions “unfair” [6, 121]. in the context of decision-making, fairness is the absence of any prejudice or favoritism toward an individual or group based on their inherent or acquired characteristics. thus, an unfair algorithm is one whose decisions are skewed toward a particular group of people. a canonical example comes from a tool used by courts in the united states to make pretrial detention and release decisions. the software, correctional offender management profiling for alternative sanctions (compas), measures the risk of a person to recommit another crime. judges use compas to decide whether to release an offender, or to keep him or her in prison.